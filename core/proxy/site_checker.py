import requests

def test_target_site(proxy_url, target_url):
    """ ØªØ³Øª Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø³Ø§ÛŒØª Ø¨Ø§ Ù¾Ø±Ø§Ú©Ø³ÛŒ Ù…Ø´Ø®Øµ """
    try:
        response = requests.get(target_url, proxies={"http": proxy_url, "https": proxy_url}, timeout=6)
        return response.status_code
    except:
        return None

def check_sites_with_proxies(target_urls, proxy_list):
    """ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ Ø¨Ø§ Ù¾Ø±Ø§Ú©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù """
    print(f"\n[*] Ø´Ø±ÙˆØ¹ Ø¨Ø±Ø±Ø³ÛŒ Ù„ÛŒØ³Øª Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ ({len(target_urls)} Ø³Ø§ÛŒØª)...\n")
    results = []
    for url in target_urls:
        print(f"ğŸŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ù…Ù†Ù‡: {url}")
        for entry in proxy_list:
            proxy = entry["proxy"]
            country = entry["country"]
            print(f"  â†’ Ø§Ø² {country} Ø¨Ø§ Ù¾Ø±Ø§Ú©Ø³ÛŒ {proxy} ... ", end="")
            status = test_target_site(proxy, url)
            if status == 200:
                print("âœ… Ø³Ø§ÛŒØª Ø¨Ø§Ø² Ø´Ø¯")
                entry["status"] = "Accessible"
            elif status:
                print(f"âš ï¸ HTTP {status}")
                entry["status"] = f"HTTP {status}"
            else:
                print("âŒ Ø§ØªØµØ§Ù„ Ù†Ø§Ù…ÙˆÙÙ‚")
                entry["status"] = "Failed"
            results.append({
                "target": url,
                "country": country,
                "proxy": proxy,
                "status": entry["status"]
            })
            # Optional: You can add sleep time to avoid overloading servers
    return results
